{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e780362f",
   "metadata": {},
   "source": [
    "# Random tree forest model after combining numeric and categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c3558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics\n",
    "\n",
    "# Import essential models and functions from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "data = pd.read_csv('student-por.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b653388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R^2 Score: 0.029098006759019034\n",
      "Mean Squared Error (MSE): 10.414881422945598\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "paid = pd.DataFrame(data['paid'])\n",
    "\n",
    "# Encoding the 'paid' column which is categorical (assuming 'yes' = 1 and 'no' = 0)\n",
    "one_hot_encoded = pd.get_dummies(paid, dtype=int)\n",
    "\n",
    "# Defining the features and target variable\n",
    "combined = pd.concat([data[['studytime']], one_hot_encoded], axis=1)\n",
    "y = data['G3']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined, y, test_size=0.2, random_state=4)\n",
    "\n",
    "# Define the number of folds\n",
    "k = 5\n",
    "\n",
    "# Initialize the KFold\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# List to store cross-validation scores\n",
    "cv_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_val_fold)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    score = model.score(X_val_fold, y_val_fold)\n",
    "    \n",
    "    # Append the score to the list of cross-validation scores\n",
    "    cv_scores.append(score)\n",
    "\n",
    "# Calculate and print the mean of the cross-validation scores\n",
    "print(\"Mean R^2 Score:\", np.mean(cv_scores))\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Calculate and print the mean squared error on the test set\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437d2537",
   "metadata": {},
   "source": [
    "justification for not removing outliers in studytime:\n",
    "1. Model Robustness: Since Random Forest can handle outliers as it makes use of the ensemble method, which is the utilising of, and combining multiple different models to obtain better predictive performance. This reduces the impact of any outliers, causing the predictive method to not be significantly affected by them.\n",
    "2. Valuable Insights: Outliers may provide valuable insights into students' performance patterns. Education is not a one-size-fits all approach, and there will be students who will perform significantly better or worse than others. Hence removing outliers would be potentially overlooking any complex, non-linear relationships that might have been detected by our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5043a34d",
   "metadata": {},
   "source": [
    "# Conclusion - interpreting the results:\n",
    "Mean R² Score:\n",
    "\n",
    "studytime : 0.04641826761747649\n",
    "\n",
    "paid : Not applicable for regression\n",
    "\n",
    "combined : 0.029098006759019034\n",
    "\n",
    "A higher R² score indicates a better fit of the model to the data. In this case, studytime has a slightly higher R² score compared to the combined model, suggesting that it explains a slightly larger proportion of the variance in G3 scores.\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "\n",
    "Mean Squared Error (MSE):\n",
    "\n",
    "studytime : 6.381007474288847\n",
    "\n",
    "paid : Not applicable for regression\n",
    "\n",
    "combined : 10.414881422945598\n",
    "\n",
    "A lower MSE indicates better accuracy of the predictions. The combined model has a higher MSE compared to the individual studytime model, suggesting that it has more error in its predictions. This is due to, when additional variables are introduced into a model, they may contribute noise or unnecessary complexity, which can result in a higher MSE.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "Based on R² Score and MSE: Despite the higher classification accuracy of paid, when considering R² score and MSE (which are more directly relevant to the regression task), studytime appears to have a slightly better performance compared to paid or the combined model.\n",
    "\n",
    "In conclusion, studytime alone may offer a simpler and more interpretable model compared to the combined model involving categorical encoding and interactions between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ec1b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d882a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
